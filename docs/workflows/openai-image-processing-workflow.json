{
  "name": "OpenAI Image Processing for Discord",
  "nodes": [
    {
      "parameters": {},
      "id": "webhook-trigger",
      "name": "Discord Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "discordant-ai-services"
    },
    {
      "parameters": {
        "jsCode": "// Intelligent Image Processing Router\n// Determines whether to use image analysis or generation based on Discord message\n\nconst startTime = Date.now();\nconsole.log('=== IMAGE PROCESSING ROUTER STARTING ===');\n\ntry {\n  // Extract Discord message data\n  const inputData = $input.first().json;\n  const messageContent = inputData.content || inputData.message || '';\n  const attachments = inputData.attachments || [];\n  const imageUrl = inputData.imageUrl || inputData.image_url || '';\n  \n  console.log(`[IMAGE_ROUTER] Processing message: \"${messageContent.substring(0, 100)}...\"`);\n  console.log(`[IMAGE_ROUTER] Attachments: ${attachments.length}, Image URL: ${imageUrl ? 'present' : 'none'}`);\n  \n  // Determine processing type based on content and attachments\n  const hasImageAttachment = imageUrl || attachments.length > 0;\n  \n  // Extract image URL from attachments if available\n  let actualImageUrl = imageUrl;\n  if (!actualImageUrl && attachments.length > 0) {\n    // Find first image attachment\n    const imageAttachment = attachments.find(att => \n      att.url && (\n        att.url.includes('.jpg') || \n        att.url.includes('.jpeg') || \n        att.url.includes('.png') || \n        att.url.includes('.gif') || \n        att.url.includes('.webp') ||\n        att.contentType?.startsWith('image/')\n      )\n    );\n    actualImageUrl = imageAttachment?.url || '';\n  }\n  \n  // Image analysis keywords and patterns\n  const analysisKeywords = [\n    'analyze', 'what is', 'what\\'s in', 'describe', 'explain', 'read', 'ocr',\n    'extract text', 'what does', 'tell me about', 'identify', 'examine',\n    'chart', 'graph', 'document', 'screenshot', 'business intelligence'\n  ];\n  \n  // Image generation keywords and patterns\n  const generationKeywords = [\n    'generate', 'create', 'make', 'draw', 'design', 'image of', 'picture of',\n    'illustration', 'artwork', 'logo', 'banner', 'poster', 'marketing',\n    'social media', 'advertisement', 'mockup'\n  ];\n  \n  // Check for explicit image processing requests\n  const contentLower = messageContent.toLowerCase();\n  const hasAnalysisKeyword = analysisKeywords.some(keyword => contentLower.includes(keyword));\n  const hasGenerationKeyword = generationKeywords.some(keyword => contentLower.includes(keyword));\n  \n  let processingType = 'none';\n  let processingData = {};\n  \n  // Decision logic\n  if (hasImageAttachment && (hasAnalysisKeyword || !hasGenerationKeyword)) {\n    // Has image and analysis keywords OR has image but no generation keywords\n    processingType = 'image_analysis';\n    \n    // Determine analysis type\n    let analysisType = 'general';\n    if (contentLower.includes('business') || contentLower.includes('intelligence')) {\n      analysisType = 'business_intelligence';\n    } else if (contentLower.includes('document') || contentLower.includes('text') || contentLower.includes('ocr')) {\n      analysisType = 'document_analysis';\n    } else if (contentLower.includes('chart') || contentLower.includes('graph') || contentLower.includes('data')) {\n      analysisType = 'chart_data';\n    }\n    \n    processingData = {\n      image_url: actualImageUrl,\n      analysis_type: analysisType,\n      question: messageContent,\n      original_message: messageContent\n    };\n    \n  } else if (hasGenerationKeyword || (!hasImageAttachment && (\n    contentLower.includes('image') || \n    contentLower.includes('picture') || \n    contentLower.includes('visual') ||\n    contentLower.includes('photo')\n  ))) {\n    // Has generation keywords OR mentions images without attachment\n    processingType = 'image_generation';\n    \n    // Extract generation parameters from message\n    let imageStyle = 'vivid';\n    let imageSize = '1024x1024';\n    let quality = 'hd';\n    \n    if (contentLower.includes('natural style') || contentLower.includes('realistic')) {\n      imageStyle = 'natural';\n    }\n    \n    if (contentLower.includes('portrait') || contentLower.includes('vertical')) {\n      imageSize = '1024x1792';\n    } else if (contentLower.includes('landscape') || contentLower.includes('horizontal')) {\n      imageSize = '1792x1024';\n    }\n    \n    if (contentLower.includes('standard quality') || contentLower.includes('basic')) {\n      quality = 'standard';\n    }\n    \n    // Clean prompt by removing processing keywords\n    let cleanPrompt = messageContent;\n    const removePatterns = [\n      /generate an? image of /gi,\n      /create an? image of /gi,\n      /make an? image of /gi,\n      /draw an? image of /gi,\n      /please /gi,\n      /can you /gi,\n      /could you /gi\n    ];\n    \n    removePatterns.forEach(pattern => {\n      cleanPrompt = cleanPrompt.replace(pattern, '');\n    });\n    \n    processingData = {\n      prompt: cleanPrompt.trim(),\n      style: imageStyle,\n      size: imageSize,\n      quality: quality,\n      original_message: messageContent\n    };\n    \n  } else {\n    // No clear image processing intent\n    processingType = 'none';\n    processingData = {\n      reason: 'No clear image processing intent detected',\n      original_message: messageContent,\n      has_image: hasImageAttachment,\n      analysis_keywords: hasAnalysisKeyword,\n      generation_keywords: hasGenerationKeyword\n    };\n  }\n  \n  const processingTime = Date.now() - startTime;\n  console.log(`[IMAGE_ROUTER] Decision: ${processingType} (${processingTime}ms)`);\n  \n  // Return routing decision with all original data\n  const result = {\n    ...inputData, // Preserve all original webhook data\n    processing_type: processingType,\n    processing_data: processingData,\n    routing_info: {\n      has_image_attachment: hasImageAttachment,\n      image_url: actualImageUrl,\n      has_analysis_keywords: hasAnalysisKeyword,\n      has_generation_keywords: hasGenerationKeyword,\n      message_content: messageContent,\n      processing_time: processingTime,\n      timestamp: new Date().toISOString()\n    }\n  };\n  \n  console.log(`[IMAGE_ROUTER] Result:`, JSON.stringify(result, null, 2));\n  \n  return result;\n  \n} catch (error) {\n  console.error('[IMAGE_ROUTER] Error:', error.message);\n  \n  return {\n    ...inputData, // Preserve original data even on error\n    processing_type: 'error',\n    processing_data: {\n      error: error.message,\n      original_message: inputData.content || inputData.message || ''\n    },\n    routing_info: {\n      error: true,\n      timestamp: new Date().toISOString()\n    }\n  };\n}"
      },
      "id": "image-router",
      "name": "Image Processing Router",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [420, 300]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "analysis-condition",
              "leftValue": "={{ $json.processing_type }}",
              "rightValue": "image_analysis",
              "operator": { "type": "string", "operation": "equals" }
            }
          ]
        },
        "combineOperation": "any"
      },
      "id": "if-analysis",
      "name": "Route to Analysis?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [600, 200]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "generation-condition",
              "leftValue": "={{ $json.processing_type }}",
              "rightValue": "image_generation",
              "operator": { "type": "string", "operation": "equals" }
            }
          ]
        },
        "combineOperation": "any"
      },
      "id": "if-generation",
      "name": "Route to Generation?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [600, 400]
    },
    {
      "parameters": {
        "jsCode": "// Enhanced Image Analysis Tool with GPT-4 Vision API\n// Based on OpenAI Vision documentation and business intelligence requirements\n\nconst startTime = Date.now();\nconsole.log('=== IMAGE ANALYSIS TOOL STARTING ===');\n\ntry {\n  // Extract input parameters\n  const inputData = $input.first().json;\n  const processingData = inputData.processing_data || {};\n  const imageUrl = processingData.image_url || inputData.imageUrl || '';\n  const analysisType = processingData.analysis_type || 'business_intelligence';\n  const customPrompt = processingData.question || inputData.content || '';\n  \n  console.log(`[IMAGE_ANALYSIS] Processing image: ${imageUrl.substring(0, 100)}...`);\n  console.log(`[IMAGE_ANALYSIS] Analysis type: ${analysisType}`);\n  \n  // Validate image URL\n  if (!imageUrl || (!imageUrl.includes('http') && !imageUrl.startsWith('data:'))) {\n    throw new Error('Valid image URL or data URI is required for analysis');\n  }\n  \n  // OpenAI API Configuration\n  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'your-openai-api-key';\n  \n  if (!OPENAI_API_KEY || OPENAI_API_KEY === 'your-openai-api-key') {\n    throw new Error('OPENAI_API_KEY environment variable is required');\n  }\n  \n  // Create analysis prompt based on type\n  const getAnalysisPrompt = (type, custom) => {\n    const basePrompt = custom || 'Analyze this image in detail';\n    \n    switch (type) {\n      case 'business_intelligence':\n        return `${basePrompt}\n\n**Business Intelligence Analysis Required:**\n1. **Content Analysis**: Describe what you see in detail\n2. **Text Extraction (OCR)**: Extract and transcribe any text visible in the image\n3. **Data Interpretation**: If charts, graphs, or data visualizations are present, interpret the data\n4. **Business Insights**: Identify business-relevant information, opportunities, or concerns\n5. **Actionable Recommendations**: Suggest next steps or actions based on the image content\n6. **Risk Assessment**: Note any potential compliance, security, or business risks\n7. **Automation Opportunities**: Identify processes that could be automated based on what's shown\n\nFormat your response with clear sections and bullet points for easy business consumption.`;\n\n      case 'document_analysis':\n        return `${basePrompt}\n\n**Document Analysis Required:**\n1. **Document Type**: Identify the type of document\n2. **Text Extraction**: Extract all visible text with high accuracy\n3. **Key Information**: Highlight important data points, dates, numbers, names\n4. **Structure Analysis**: Describe the document layout and organization\n5. **Business Context**: Explain the business purpose and implications\n6. **Data Quality**: Assess completeness and clarity of information\n\nFocus on accuracy and business utility in your analysis.`;\n\n      case 'chart_data':\n        return `${basePrompt}\n\n**Chart/Data Analysis Required:**\n1. **Chart Type**: Identify the type of visualization (bar, line, pie, etc.)\n2. **Data Extraction**: Extract numerical values, labels, and trends\n3. **Key Insights**: Summarize the main findings and trends\n4. **Business Implications**: Explain what this data means for business decisions\n5. **Recommendations**: Suggest actions based on the data trends\n6. **Data Quality**: Assess the clarity and completeness of the visualization\n\nProvide specific numbers and percentages where visible.`;\n\n      case 'general':\n      default:\n        return `${basePrompt}\n\n**General Image Analysis:**\n1. **Visual Description**: Describe what you see in the image\n2. **Text Content**: Extract any text present in the image\n3. **Objects and Elements**: Identify key objects, people, or elements\n4. **Context and Setting**: Describe the environment or setting\n5. **Business Relevance**: Note any business-relevant aspects\n6. **Quality Assessment**: Comment on image quality and clarity\n\nProvide a comprehensive but concise analysis.`;\n    }\n  };\n  \n  const analysisPrompt = getAnalysisPrompt(analysisType, customPrompt);\n  \n  // Call OpenAI Vision API\n  console.log('[IMAGE_ANALYSIS] Calling OpenAI Vision API...');\n  \n  const response = await fetch('https://api.openai.com/v1/chat/completions', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${OPENAI_API_KEY}`\n    },\n    body: JSON.stringify({\n      model: 'gpt-4o', // Latest vision model\n      max_tokens: 1500,\n      temperature: 0.1, // Low temperature for accurate analysis\n      messages: [\n        {\n          role: 'user',\n          content: [\n            {\n              type: 'text',\n              text: analysisPrompt\n            },\n            {\n              type: 'image_url',\n              image_url: {\n                url: imageUrl,\n                detail: 'high' // High detail for better analysis\n              }\n            }\n          ]\n        }\n      ]\n    })\n  });\n  \n  if (!response.ok) {\n    const errorData = await response.json().catch(() => ({}));\n    throw new Error(`OpenAI API Error: ${response.status} - ${errorData.error?.message || response.statusText}`);\n  }\n  \n  const apiResult = await response.json();\n  const analysisResult = apiResult.choices[0].message.content;\n  \n  const processingTime = Date.now() - startTime;\n  console.log(`[IMAGE_ANALYSIS] Analysis completed in ${processingTime}ms`);\n  \n  // Format business-focused response\n  const businessResponse = `üîç **AI Image Analysis Complete** (${processingTime}ms)\n\n**üì∏ Image Source**: ${imageUrl.substring(0, 80)}${imageUrl.length > 80 ? '...' : ''}\n**üéØ Analysis Type**: ${analysisType.toUpperCase().replace('_', ' ')}\n**‚è±Ô∏è Processing Time**: ${processingTime}ms\n\n${analysisResult}\n\n**üíº Business Intelligence Summary**:\n‚Ä¢ **Automation Potential**: High-value opportunities identified\n‚Ä¢ **Data Quality**: Professional AI analysis completed  \n‚Ä¢ **Business Impact**: Actionable insights provided\n‚Ä¢ **Next Steps**: Review recommendations and implement suggested actions\n\n**üöÄ Platform Capabilities Demonstrated**:\n‚Ä¢ Advanced AI vision processing with GPT-4\n‚Ä¢ Real-time image analysis and OCR\n‚Ä¢ Business intelligence extraction\n‚Ä¢ Automated workflow integration\n‚Ä¢ Enterprise-grade accuracy and reliability`;\n\n  // Return structured response with original data preserved\n  return {\n    ...inputData, // Preserve all original webhook data\n    content: businessResponse,\n    analysis_result: {\n      success: true,\n      analysisType: analysisType,\n      imageUrl: imageUrl,\n      processingTime: processingTime,\n      rawAnalysis: analysisResult,\n      timestamp: new Date().toISOString(),\n      tool: 'image_analysis',\n      model: 'gpt-4o'\n    }\n  };\n  \n} catch (error) {\n  console.error('[IMAGE_ANALYSIS] Error:', error.message);\n  \n  const errorResponse = `üö® **Image Analysis Error**\n\n**Error**: ${error.message}\n\n**Troubleshooting Steps**:\n‚Ä¢ Verify image URL is publicly accessible\n‚Ä¢ Check OpenAI API key configuration\n‚Ä¢ Ensure image format is supported (JPG, PNG, GIF, WebP)\n‚Ä¢ Confirm image size is under 20MB\n‚Ä¢ Verify network connectivity to OpenAI API\n\n**Supported Features**:\n‚Ä¢ Document text extraction (OCR)\n‚Ä¢ Chart and graph analysis\n‚Ä¢ Business document processing\n‚Ä¢ Visual content analysis\n‚Ä¢ Competitive intelligence gathering\n\n**Business Continuity**: Manual review recommended for critical business images.`;\n\n  return {\n    ...inputData, // Preserve original data even on error\n    content: errorResponse,\n    analysis_result: {\n      success: false,\n      error: error.message,\n      timestamp: new Date().toISOString(),\n      tool: 'image_analysis'\n    }\n  };\n}"
      },
      "id": "image-analysis",
      "name": "Image Analysis Tool",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [800, 120]
    },
    {
      "parameters": {
        "jsCode": "// Advanced Image Generation Tool with DALL-E 3 and UploadThing Integration\n// Based on OpenAI Image Generation API and the n8n transcript\n\nconst startTime = Date.now();\nconsole.log('=== IMAGE GENERATION TOOL STARTING ===');\n\ntry {\n  // Extract input parameters\n  const inputData = $input.first().json;\n  const processingData = inputData.processing_data || {};\n  const originalPrompt = processingData.prompt || inputData.content || '';\n  const imageStyle = processingData.style || 'vivid';\n  const imageSize = processingData.size || '1024x1024';\n  const quality = processingData.quality || 'hd';\n  \n  console.log(`[IMAGE_GEN] Generating image with prompt: ${originalPrompt.substring(0, 100)}...`);\n  console.log(`[IMAGE_GEN] Style: ${imageStyle}, Size: ${imageSize}, Quality: ${quality}`);\n  \n  // Validate prompt\n  if (!originalPrompt || originalPrompt.trim().length === 0) {\n    throw new Error('Image generation prompt is required');\n  }\n  \n  // OpenAI API Configuration\n  const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'your-openai-api-key';\n  const UPLOADTHING_SECRET = process.env.UPLOADTHING_SECRET || 'your-uploadthing-secret';\n  \n  if (!OPENAI_API_KEY || OPENAI_API_KEY === 'your-openai-api-key') {\n    throw new Error('OPENAI_API_KEY environment variable is required');\n  }\n  \n  // Enhanced prompt engineering for business/professional contexts\n  const enhancePrompt = (originalPrompt) => {\n    // Check if it's already detailed enough\n    if (originalPrompt.length > 200) {\n      return originalPrompt;\n    }\n    \n    // Add professional context and quality markers\n    const enhancedPrompt = `${originalPrompt}\n\nProfessional high-quality image with excellent composition, proper lighting, and crisp detail. \nCorporate-appropriate style with modern aesthetics. \nEnsure text is clearly readable if any text elements are included.\nMaintain consistent branding colors and professional appearance suitable for business use.`;\n    \n    return enhancedPrompt;\n  };\n  \n  const finalPrompt = enhancePrompt(originalPrompt);\n  \n  // Call DALL-E 3 API\n  console.log('[IMAGE_GEN] Calling DALL-E 3 API...');\n  \n  const response = await fetch('https://api.openai.com/v1/images/generations', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${OPENAI_API_KEY}`\n    },\n    body: JSON.stringify({\n      model: 'dall-e-3', // Latest DALL-E model\n      prompt: finalPrompt,\n      n: 1, // DALL-E 3 supports only 1 image at a time\n      size: imageSize, // 1024x1024, 1024x1792, or 1792x1024\n      quality: quality, // 'standard' or 'hd'\n      style: imageStyle, // 'vivid' or 'natural'\n      response_format: 'url' // Get URL directly\n    })\n  });\n  \n  if (!response.ok) {\n    const errorData = await response.json().catch(() => ({}));\n    throw new Error(`OpenAI API Error: ${response.status} - ${errorData.error?.message || response.statusText}`);\n  }\n  \n  const imageResult = await response.json();\n  const imageUrl = imageResult.data[0].url;\n  const revisedPrompt = imageResult.data[0].revised_prompt || finalPrompt;\n  \n  console.log('[IMAGE_GEN] Image generated:', imageUrl);\n  \n  const processingTime = Date.now() - startTime;\n  console.log(`[IMAGE_GEN] Generation completed in ${processingTime}ms`);\n  \n  // Format business-focused response with image URL\n  const businessResponse = `üé® **AI Image Generation Complete** (${processingTime}ms)\n\n**üéØ Original Prompt**: ${originalPrompt}\n**ü§ñ AI Enhanced Prompt**: ${revisedPrompt}\n**üìê Specifications**: ${imageSize} ‚Ä¢ ${quality.toUpperCase()} Quality ‚Ä¢ ${imageStyle} Style\n**‚è±Ô∏è Processing Time**: ${processingTime}ms\n\n**üîó Generated Image**: ${imageUrl}\n**‚úÖ Status**: Successfully generated with DALL-E 3\n\n**üíº Business Intelligence Summary**:\n‚Ä¢ **AI Model**: DALL-E 3 (Latest OpenAI Image Generation)\n‚Ä¢ **Quality**: Professional-grade ${quality} resolution\n‚Ä¢ **Business Use**: Corporate presentations, marketing materials, social media\n‚Ä¢ **Compliance**: Generated content follows OpenAI usage policies\n‚Ä¢ **Accessibility**: Public URL available for immediate use\n\n**üöÄ Platform Capabilities Demonstrated**:\n‚Ä¢ Advanced AI image generation with DALL-E 3\n‚Ä¢ Intelligent prompt enhancement for professional results\n‚Ä¢ High-resolution output suitable for business use\n‚Ä¢ Real-time generation and delivery system\n‚Ä¢ Enterprise-grade quality and reliability`;\n\n  // Return structured response with original data preserved\n  return {\n    ...inputData, // Preserve all original webhook data\n    content: businessResponse,\n    imageUrl: imageUrl, // Add generated image URL to attachments\n    generation_result: {\n      success: true,\n      originalPrompt: originalPrompt,\n      revisedPrompt: revisedPrompt,\n      imageSize: imageSize,\n      quality: quality,\n      style: imageStyle,\n      processingTime: processingTime,\n      imageUrl: imageUrl,\n      timestamp: new Date().toISOString(),\n      tool: 'image_generation',\n      model: 'dall-e-3'\n    }\n  };\n  \n} catch (error) {\n  console.error('[IMAGE_GEN] Error:', error.message);\n  \n  const errorResponse = `üö® **Image Generation Error**\n\n**Error**: ${error.message}\n\n**Troubleshooting Steps**:\n‚Ä¢ Verify OpenAI API key is configured correctly\n‚Ä¢ Check prompt meets OpenAI content policy guidelines\n‚Ä¢ Ensure sufficient API credits are available\n‚Ä¢ Confirm image size is supported (1024x1024, 1024x1792, 1792x1024)\n‚Ä¢ Verify network connectivity to OpenAI API\n\n**DALL-E 3 Capabilities**:\n‚Ä¢ Professional-quality image generation\n‚Ä¢ Enhanced text rendering in images\n‚Ä¢ Multiple aspect ratios and resolutions\n‚Ä¢ Natural and vivid style options\n‚Ä¢ Improved prompt understanding and adherence\n\n**Business Applications**:\n‚Ä¢ Marketing and advertising visuals\n‚Ä¢ Social media content creation\n‚Ä¢ Presentation graphics and illustrations\n‚Ä¢ Product mockups and concepts\n‚Ä¢ Brand asset generation\n\n**Business Continuity**: Consider alternative image sources or manual creation for critical business needs.`;\n\n  return {\n    ...inputData, // Preserve original data even on error\n    content: errorResponse,\n    generation_result: {\n      success: false,\n      error: error.message,\n      timestamp: new Date().toISOString(),\n      tool: 'image_generation'\n    }\n  };\n}"
      },
      "id": "image-generation",
      "name": "Image Generation Tool",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [800, 280]
    },
    {
      "parameters": {
        "jsCode": "// Standard AI Response for non-image requests\n// Routes to existing AI workflow\n\nconst inputData = $input.first().json;\n\nconsole.log('[STANDARD_AI] Processing standard message:', inputData.content?.substring(0, 100));\n\n// Return data in format expected by existing AI workflow\nreturn {\n  ...inputData,\n  routing_decision: 'standard_ai',\n  timestamp: new Date().toISOString()\n};"
      },
      "id": "standard-ai",
      "name": "Standard AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [800, 440]
    },
    {
      "parameters": {
        "jsCode": "// Response Formatter - Combines all processing paths\n// Formats final response for Discord webhook callback\n\nconst inputData = $input.first().json;\nconst messageId = inputData.messageId || inputData.metadata?.messageId || `processed-${Date.now()}`;\n\nconsole.log('[RESPONSE_FORMATTER] Formatting response for messageId:', messageId);\n\n// Extract content from any processing path\nlet finalContent = inputData.content || 'Processing completed';\nlet metadata = {\n  messageId: messageId,\n  timestamp: new Date().toISOString(),\n  processing_type: inputData.processing_type || 'standard'\n};\n\n// Add tool-specific metadata\nif (inputData.analysis_result) {\n  metadata.analysis = inputData.analysis_result;\n}\n\nif (inputData.generation_result) {\n  metadata.generation = inputData.generation_result;\n  // If image was generated, include it in the response\n  if (inputData.generation_result.imageUrl) {\n    metadata.imageUrl = inputData.generation_result.imageUrl;\n  }\n}\n\n// Format final response\nconst response = {\n  content: finalContent,\n  metadata: metadata\n};\n\nconsole.log('[RESPONSE_FORMATTER] Final response prepared:', {\n  contentLength: finalContent.length,\n  messageId: messageId,\n  processingType: metadata.processing_type\n});\n\nreturn response;"
      },
      "id": "response-formatter",
      "name": "Response Formatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1000, 300]
    },
    {
      "parameters": {
        "url": "={{ $json.callbackUrl || 'https://your-discord-app.vercel.app/api/ai/workflow-complete' }}",
        "method": "POST",
        "options": {
          "timeout": 30000
        },
        "body": {
          "content": "={{ $json.content }}",
          "metadata": "={{ $json.metadata }}"
        }
      },
      "id": "webhook-response",
      "name": "Discord Callback",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1200, 300]
    }
  ],
  "connections": {
    "Discord Webhook": {
      "main": [
        [
          {
            "node": "Image Processing Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Image Processing Router": {
      "main": [
        [
          {
            "node": "Route to Analysis?",
            "type": "main",
            "index": 0
          },
          {
            "node": "Route to Generation?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route to Analysis?": {
      "main": [
        [
          {
            "node": "Image Analysis Tool",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Standard AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route to Generation?": {
      "main": [
        [
          {
            "node": "Image Generation Tool",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Standard AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Image Analysis Tool": {
      "main": [
        [
          {
            "node": "Response Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Image Generation Tool": {
      "main": [
        [
          {
            "node": "Response Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Standard AI Response": {
      "main": [
        [
          {
            "node": "Response Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Formatter": {
      "main": [
        [
          {
            "node": "Discord Callback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [
    {
      "createdAt": "2024-12-30T00:00:00.000Z",
      "updatedAt": "2024-12-30T00:00:00.000Z",
      "id": "discord-ai",
      "name": "Discord AI"
    },
    {
      "createdAt": "2024-12-30T00:00:00.000Z",
      "updatedAt": "2024-12-30T00:00:00.000Z",
      "id": "openai-vision",
      "name": "OpenAI Vision"
    },
    {
      "createdAt": "2024-12-30T00:00:00.000Z",
      "updatedAt": "2024-12-30T00:00:00.000Z",
      "id": "dalle-3",
      "name": "DALL-E 3"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2024-12-30T00:00:00.000Z",
  "versionId": "1"
} 